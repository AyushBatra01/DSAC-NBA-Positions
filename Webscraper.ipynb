{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ea659df-7b4d-4f5c-ade3-440529d95c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2460d53e-bff7-4f20-9e3e-1b8d7f22820a",
   "metadata": {},
   "source": [
    "# Advanced Stats Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b78fe0-79e9-4108-81fd-ccc3dba72a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURL(year):\n",
    "    return f\"https://www.basketball-reference.com/leagues/NBA_{year}.html\"\n",
    "\n",
    "def getSoup(year):\n",
    "    url = getURL(year)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def headers(table):\n",
    "    th = table.find('thead').find_all('tr')[1]\n",
    "    th = th.find_all('th')\n",
    "    labels = []\n",
    "    for i in range(len(th)):\n",
    "        if th[i].text in labels:\n",
    "            labels.append(f\"Opp {th[i].text}\")\n",
    "        else:\n",
    "            labels.append(th[i].text)\n",
    "    return labels\n",
    "\n",
    "def tableData(table):\n",
    "    labels = headers(table)\n",
    "    data = []\n",
    "    for lab in labels:\n",
    "        data.append([])\n",
    "    rows = table.find('tbody').find_all('tr')\n",
    "    for r in rows:\n",
    "        if r.get('id') is not None:\n",
    "            continue\n",
    "        tm = r.find('th').text\n",
    "        data[0].append(tm)\n",
    "        td = r.find_all('td')\n",
    "        for i in range(len(td)):\n",
    "            data[i + 1].append(td[i].text)\n",
    "    dataDict = {}\n",
    "    for i in range(len(labels)):\n",
    "        dataDict[labels[i]] = data[i]\n",
    "    return pd.DataFrame(dataDict)\n",
    "\n",
    "def removeStar(text):\n",
    "    return text.replace(\"*\", \"\")\n",
    "\n",
    "def cleanCols(table):\n",
    "    dropCols = ['Rk', '\\xa0', 'Opp \\xa0', 'Arena', 'Attend.', 'Attend./G']\n",
    "    table = table.drop(columns = dropCols)\n",
    "    notNumeric = ['Team']\n",
    "    for c in table.columns.tolist():\n",
    "        if c in notNumeric:\n",
    "            continue\n",
    "        table[c] = pd.to_numeric(table[c])\n",
    "    table['Team'] = table['Team'].apply(removeStar)\n",
    "    return table\n",
    "\n",
    "def advancedTable(year):\n",
    "    soup = getSoup(year)\n",
    "    table = soup.find('table', {'id' : 'advanced-team'})\n",
    "    df = tableData(table)\n",
    "    df = cleanCols(df)\n",
    "    return df\n",
    "\n",
    "def gatherStats(start, end):\n",
    "    df_list = []\n",
    "    for i in tqdm(range(start, end + 1)):\n",
    "        table = advancedTable(i)\n",
    "        time.sleep(2)\n",
    "        table['Season'] = i\n",
    "        df_list.append(table)\n",
    "    big_df = pd.concat(df_list)\n",
    "    seas = big_df.pop('Season')\n",
    "    big_df.insert(1, 'Season', seas)\n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004c0007-cab3-4e05-bfdb-3cb365e0bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_df = gatherStats(1980, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612464c8-cb1d-451b-99ba-2c25385131ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_df.to_csv('DATA/advanced.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613d8836-a6f9-42c7-8637-b4bfb3eb796b",
   "metadata": {},
   "source": [
    "# All-NBA Players Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0245cdf9-7f94-467e-8967-ab52023f1c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURL(year):\n",
    "    return f\"https://www.basketball-reference.com/awards/awards_{year}.html\"\n",
    "\n",
    "def getSoup(year):\n",
    "    url = getURL(year)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def headers(table):\n",
    "    th = table.find('thead').find_all('tr')[1]\n",
    "    th = th.find_all('th')\n",
    "    labels = []\n",
    "    for i in range(len(th)):\n",
    "        labels.append(th[i].text)\n",
    "    return labels\n",
    "\n",
    "def tableData(table):\n",
    "    labels = headers(table)\n",
    "    data = []\n",
    "    for lab in labels:\n",
    "        data.append([])\n",
    "    rows = table.find('tbody').find_all('tr')\n",
    "    for r in rows:\n",
    "        if r.get('id') is not None:\n",
    "            continue\n",
    "        tm = r.find('th').text\n",
    "        data[0].append(tm)\n",
    "        td = r.find_all('td')\n",
    "        for i in range(len(td)):\n",
    "            data[i + 1].append(td[i].text)\n",
    "    dataDict = {}\n",
    "    for i in range(len(labels)):\n",
    "        dataDict[labels[i]] = data[i]\n",
    "    return pd.DataFrame(dataDict)\n",
    "\n",
    "def cleanCols(table):\n",
    "    notNumeric = ['# Tm', 'Pos', 'Player', 'Tm']\n",
    "    for c in table.columns.tolist():\n",
    "        if c in notNumeric:\n",
    "            continue\n",
    "        table[c] = pd.to_numeric(table[c])\n",
    "    table['3P%'] = table['3P%'].fillna(0)\n",
    "    return table\n",
    "\n",
    "def allNBATable(year):\n",
    "    soup = getSoup(year)\n",
    "    table = soup.find('table', {'id' : 'leading_all_nba'})\n",
    "    df = tableData(table)\n",
    "    df = cleanCols(df)\n",
    "    return df\n",
    "\n",
    "def gatherStats(start, end):\n",
    "    df_list = []\n",
    "    for i in tqdm(range(start, end + 1)):\n",
    "        table = allNBATable(i)\n",
    "        time.sleep(2)\n",
    "        table['Season'] = i\n",
    "        df_list.append(table)\n",
    "    big_df = pd.concat(df_list)\n",
    "    seas = big_df.pop('Season')\n",
    "    big_df.insert(3, 'Season', seas)\n",
    "    return big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2158122-15af-4902-b0b0-01b2b72c0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "allnba = gatherStats(1980, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8e0e0-6bf9-4147-85b3-6ac96402dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "allnba.to_csv('DATA/allnba.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e2135-f5b7-417f-a421-2bf6d735b448",
   "metadata": {},
   "source": [
    "# Playoff Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1c01f0-5196-4633-bf31-52835df201ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getURL(year):\n",
    "    return f\"https://www.basketball-reference.com/playoffs/NBA_{year}.html\"\n",
    "\n",
    "def getSoup(year):\n",
    "    url = getURL(year)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "def deleteConf(text):\n",
    "    text = text.replace(\"Eastern \", \"\")\n",
    "    text = text.replace(\"Western \", \"\")\n",
    "    return text\n",
    "\n",
    "def resultsToDF(results, year):\n",
    "    data = {'Team' : [],\n",
    "            'Season' : [],\n",
    "            'Result' : []}\n",
    "    for team, res in results.items():\n",
    "        data['Team'].append(team)\n",
    "        data['Result'].append(res)\n",
    "        data['Season'].append(year)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def playoffResults(year):\n",
    "    s = getSoup(year)\n",
    "    t = s.find('table', {'id' : 'all_playoffs'})\n",
    "    b = t.find('tbody')\n",
    "    rows = b.find_all('tr')\n",
    "    results = {}\n",
    "    for i in range(len(rows)):\n",
    "        if rows[i].find('strong') is not None:\n",
    "            res = rows[i].find_all('td')[1]\n",
    "            a = res.find_all('a')\n",
    "            if rows[i].find('strong').text == 'Finals':\n",
    "                winner = a[0].text\n",
    "                loser = a[1].text\n",
    "                results[winner] = 'Won Finals'\n",
    "                results[loser] = 'Lost Finals'\n",
    "            else:\n",
    "                loser = a[1].text\n",
    "                results[loser] = deleteConf(rows[i].find('strong').text)\n",
    "    return resultsToDF(results, year)\n",
    "\n",
    "def allPlayoffs(start, end):\n",
    "    df_list = []\n",
    "    for i in tqdm(range(start, end + 1)):\n",
    "        res_df = playoffResults(i)\n",
    "        time.sleep(2)\n",
    "        df_list.append(res_df)\n",
    "    return pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e39988-0b94-440f-915e-e9ca717c4fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_df = allPlayoffs(1980, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3139f8-92f8-4bfa-bb6d-d99fdc0c8a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "playoff_df.to_csv('DATA/playoff_results.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
